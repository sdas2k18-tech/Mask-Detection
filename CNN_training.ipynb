{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data=np.load('data.npy')\n",
    "target=np.load('target.npy')\n",
    "\n",
    "#loading the save numpy arrays in the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#The first CNN layer followed by Relu and MaxPooling layers\n",
    "\n",
    "model.add(Conv2D(100,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#The second convolution layer followed by Relu and MaxPooling layers\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "#Flatten layer to stack the output convolutions from second convolution layer\n",
    "model.add(Dense(50,activation='relu'))\n",
    "#Dense layer of 64 neurons\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "#The Final layer with two outputs for two categories\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 990 samples, validate on 248 samples\n",
      "Epoch 1/20\n",
      "990/990 [==============================] - 55s 55ms/step - loss: 0.6812 - accuracy: 0.5455 - val_loss: 0.5849 - val_accuracy: 0.7419\n",
      "Epoch 2/20\n",
      "990/990 [==============================] - 52s 53ms/step - loss: 0.4556 - accuracy: 0.7929 - val_loss: 0.3121 - val_accuracy: 0.8831\n",
      "Epoch 3/20\n",
      "990/990 [==============================] - 50s 51ms/step - loss: 0.2717 - accuracy: 0.9030 - val_loss: 0.3089 - val_accuracy: 0.8548\n",
      "Epoch 4/20\n",
      "990/990 [==============================] - 54s 55ms/step - loss: 0.1915 - accuracy: 0.9303 - val_loss: 0.2015 - val_accuracy: 0.9395\n",
      "Epoch 5/20\n",
      "990/990 [==============================] - 49s 50ms/step - loss: 0.1271 - accuracy: 0.9606 - val_loss: 0.3713 - val_accuracy: 0.8669\n",
      "Epoch 6/20\n",
      "990/990 [==============================] - 52s 52ms/step - loss: 0.1467 - accuracy: 0.9485 - val_loss: 0.3332 - val_accuracy: 0.8710\n",
      "Epoch 7/20\n",
      "990/990 [==============================] - 61s 62ms/step - loss: 0.1274 - accuracy: 0.9596 - val_loss: 0.1931 - val_accuracy: 0.9274\n",
      "Epoch 8/20\n",
      "990/990 [==============================] - 72s 73ms/step - loss: 0.0645 - accuracy: 0.9747 - val_loss: 0.1870 - val_accuracy: 0.9274\n",
      "Epoch 9/20\n",
      "990/990 [==============================] - 70s 71ms/step - loss: 0.0614 - accuracy: 0.9798 - val_loss: 0.2356 - val_accuracy: 0.9274\n",
      "Epoch 10/20\n",
      "990/990 [==============================] - 77s 78ms/step - loss: 0.0443 - accuracy: 0.9889 - val_loss: 0.2519 - val_accuracy: 0.9315\n",
      "Epoch 11/20\n",
      "990/990 [==============================] - 75s 76ms/step - loss: 0.0457 - accuracy: 0.9869 - val_loss: 0.2409 - val_accuracy: 0.9274\n",
      "Epoch 12/20\n",
      "990/990 [==============================] - 77s 78ms/step - loss: 0.0392 - accuracy: 0.9848 - val_loss: 0.2132 - val_accuracy: 0.9274\n",
      "Epoch 13/20\n",
      "990/990 [==============================] - 74s 75ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 0.2439 - val_accuracy: 0.9315\n",
      "Epoch 14/20\n",
      "990/990 [==============================] - 73s 73ms/step - loss: 0.0563 - accuracy: 0.9828 - val_loss: 0.1821 - val_accuracy: 0.9435\n",
      "Epoch 15/20\n",
      "990/990 [==============================] - 71s 72ms/step - loss: 0.0303 - accuracy: 0.9899 - val_loss: 0.1961 - val_accuracy: 0.9355\n",
      "Epoch 16/20\n",
      "990/990 [==============================] - 75s 76ms/step - loss: 0.0320 - accuracy: 0.9919 - val_loss: 0.3101 - val_accuracy: 0.9153\n",
      "Epoch 17/20\n",
      "990/990 [==============================] - 75s 75ms/step - loss: 0.0267 - accuracy: 0.9879 - val_loss: 0.2655 - val_accuracy: 0.9395\n",
      "Epoch 18/20\n",
      "990/990 [==============================] - 74s 75ms/step - loss: 0.0431 - accuracy: 0.9879 - val_loss: 0.2398 - val_accuracy: 0.9315\n",
      "Epoch 19/20\n",
      "990/990 [==============================] - 73s 73ms/step - loss: 0.0175 - accuracy: 0.9929 - val_loss: 0.2542 - val_accuracy: 0.9355\n",
      "Epoch 20/20\n",
      "256/990 [======>.......................] - ETA: 50s - loss: 0.0241 - accuracy: 0.9922"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "history=model.fit(train_data,train_target,epochs=20,callbacks=[checkpoint],validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='training loss')\n",
    "plt.plot(history.history['val_loss'],label='validation loss')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],'r',label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 2s 17ms/step\n",
      "[0.13264024775961172, 0.9637681245803833]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(test_data,test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
